{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fef2305a",
   "metadata": {},
   "source": [
    "# Cap√≠tulo 7. Aprendizaje en Conjunto y Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2713d5e-a6d1-4096-977d-cb263dbf75c9",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">1.Clasificador de Votaciones </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb2054af-cd41-402b-b9b4-0e24ce920215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importa las librer√≠as, por favor y gracias <3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fec6406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importa los clasificadores\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "#Este no lo conoc√≠an, se los presento\n",
    "#Este VotingClassifier va a recibir los modelos y va a contar los votos de los resultados (como el INE para los mexas)\n",
    "from sklearn.ensemble import VotingClassifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25136a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gmat</th>\n",
       "      <th>gpa</th>\n",
       "      <th>work_experience</th>\n",
       "      <th>admitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>780</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>750</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>690</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>710</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>680</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gmat  gpa  work_experience  admitted\n",
       "0   780  4.0                3         1\n",
       "1   750  3.9                4         1\n",
       "2   690  3.3                3         0\n",
       "3   710  3.7                5         1\n",
       "4   680  3.9                4         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trae el set de datos\n",
    "candidates = {'gmat': [780,750,690,710,680,730,690,720,740,690,610,690,710,680,770,610,580,650,540,590,620,600,550,550,570,670,660,580,650,660,640,620,660,660,680,650,670,580,590,690],\n",
    "              'gpa': [4,3.9,3.3,3.7,3.9,3.7,2.3,3.3,3.3,1.7,2.7,3.7,3.7,3.3,3.3,3,2.7,3.7,2.7,2.3,3.3,2,2.3,2.7,3,3.3,3.7,2.3,3.7,3.3,3,2.7,4,3.3,3.3,2.3,2.7,3.3,1.7,3.7],\n",
    "              'work_experience': [3,4,3,5,4,6,1,4,5,1,3,5,6,4,3,1,4,6,2,3,2,1,4,1,2,6,4,2,6,5,1,2,4,6,5,1,2,1,4,5],\n",
    "              'admitted': [1,1,0,1,0,1,0,1,1,0,0,1,1,0,1,0,0,1,0,0,1,0,0,0,0,1,1,0,1,1,0,0,1,1,1,0,0,0,0,1]\n",
    "              }\n",
    "#Es sencillo pero, es trabajo honesto\n",
    "df = pd.DataFrame(candidates,columns= ['gmat', 'gpa','work_experience','admitted'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1082a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir el dataframe en dos: los datos a predecir y los datos predichos\n",
    "x = df[['gpa','gmat','work_experience']]\n",
    "y = df['admitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c98a2bfe-a89b-4870-a84d-0e9052614246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importa el train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Divide los datos\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, random_state = 42, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4c65958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrena los modelos\n",
    "    #Genera los objetos\n",
    "svm = SVC()\n",
    "    #Establece una profundidad m√°xima de 2 en el √°rbol de decisi√≥n\n",
    "arbol = DecisionTreeClassifier(max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52059602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('svm', SVC(probability=True)),\n",
       "                             ('arbol', DecisionTreeClassifier(max_depth=2))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Genera un objeto para el votingClassifier\n",
    "votos = VotingClassifier(estimators=[ (\"svm\", svm), (\"arbol\", arbol)],voting=\"hard\")\n",
    "votos.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18526e47-02d0-48d2-be85-03de1cc32f26",
   "metadata": {},
   "source": [
    "En caso de querer una votaci√≥n suave, poner en voting=\"Soft\" (m√°s adelante se ejemplifica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b0099ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 0.6666666666666666\n",
      "DecisionTreeClassifier 0.8333333333333334\n",
      "VotingClassifier 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "#Calcular la exactitud de los modelos con accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "#Ciclar a tr√°ves de los 3 modelos que estamos desarrolando \n",
    "for i in (svm, arbol, votos):\n",
    "    #Ajustar\n",
    "    i.fit(x_train,y_train)\n",
    "    #Predecir los datos del x_test \n",
    "    y_pred = i.predict(x_test)\n",
    "    print(i.__class__.__name__,\n",
    "        #Arrojar el puntaje de exactitud \n",
    "         accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18402c9c-653a-4ea8-b4d9-e4724e071981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC 0.6666666666666666\n",
      "DecisionTreeClassifier 0.8333333333333334\n",
      "VotingClassifier 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "#En caso de querer un margen suave se tiene que hacer ciertas modificaciones\n",
    "svm = SVC(probability=True)\n",
    "votos = VotingClassifier(estimators=[ (\"svm\", svm), (\"arbol\", arbol)],voting=\"soft\")\n",
    "votos.fit(x_train,y_train)\n",
    "#Calcular la exactitud de los modelos con accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "#Ciclar a tr√°ves de los 3 modelos que estamos desarrolando \n",
    "for i in (svm, arbol, votos):\n",
    "    #Ajustar\n",
    "    i.fit(x_train,y_train)\n",
    "    #Predecir los datos del x_test \n",
    "    y_pred = i.predict(x_test)\n",
    "    print(i.__class__.__name__,\n",
    "        #Arrojar el puntaje de exactitud \n",
    "         accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c3edf5-465c-422e-9937-c1ef93ef1d8d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3f16ec-1504-4c75-9b37-3f9e3b9a8d30",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">2. Bagging y Pasting </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6e759e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar el clasificador BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "#Genera el objeto a ra√≠z de un √°rbol de decisi√≥n (puede ser el que quieran)\n",
    "bagging = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                           #cantidad de (en este caso) √°rboles de decisi√≥n \n",
    "                           n_estimators=100,\n",
    "                            #La cantidad de datos que tomar√° de una muestra\n",
    "                           max_samples=10,\n",
    "                           #Bagging=True; Pasting=False\n",
    "                           bootstrap=True)\n",
    "bagging.fit(x_train,y_train)\n",
    "y_pred = bagging.predict(x_test)\n",
    "#Aunque dar√° un puntaje similar al clasificador de votaciones, esto se debe al set de datos peque√±o.\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18cfcd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacer el ejemplo con pasting pero utilizar ahora SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "pasting = BaggingClassifier(SVC(),\n",
    "                           n_estimators=50,\n",
    "                           max_samples=15,\n",
    "                           bootstrap=False)\n",
    "pasting.fit(x_train,y_train)\n",
    "y_pred = pasting.predict(x_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28824b9e-4165-4ea8-b13e-0938f390fd41",
   "metadata": {},
   "source": [
    "Pasting no suele ser utilizado en ejemplos reales. El puntaje de exactitud evidencia que es un p√©simo modelo ‚ùå "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac40368f-94c6-4f23-95bd-a46bb11e3c3a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85410bce",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">2.1 Evaluaci√≥n Out-of-Bag  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86fa0883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8928571428571429"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importar BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                           n_estimators=100,\n",
    "                           max_samples=10,\n",
    "                            #Poner oob_score=True para poder hacer la evaluaci√≥n\n",
    "                           bootstrap=True, oob_score=True)\n",
    "#Ajustar\n",
    "bagging.fit(x_train,y_train)\n",
    "#Visualiza el puntaje OOB\n",
    "bagging.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41ba6b0-fef1-468d-8f7e-c1d9e3b11617",
   "metadata": {},
   "source": [
    "Este puntaje es un par√°metro extra, puedes concluir si hay o no un ajuste con base a los par√°metros que ya sacaste y el puntaje OOB üíØ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5fa093-a7d5-414c-baae-3a64a5b57fcb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93cac2e-396d-43a1-808c-10b74abdfcaf",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">3. Random Subspace </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd1d44b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_features=2,\n",
       "                  max_samples=10, n_estimators=100, oob_score=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacer un Bagging como los anteriores\n",
    "bagging = BaggingClassifier(DecisionTreeClassifier(),\n",
    "                           n_estimators=100,\n",
    "                           max_samples=10,\n",
    "                           bootstrap=True,\n",
    "                            #Max_features le dice que solo tomar√° 2 variables\n",
    "                           max_features=2,\n",
    "                           oob_score=True)\n",
    "#Ajustar\n",
    "bagging.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9d0ec76-0bb1-4231-8eb6-4103d64a48ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizar el puntaje de exactitud\n",
    "bagging.fit(x_train,y_train)\n",
    "y_pred=bagging.predict(x_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846b2873",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">4. Random Forest </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "653fe19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Hacer RandomForestClassifier, establecer los par√°metros similares al bagging\n",
    "rf = RandomForestClassifier(n_estimators=100,\n",
    "                           max_leaf_nodes=4,\n",
    "                           max_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c94913c6-da7a-4e48-8c0a-36d06e1c810c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=2, max_leaf_nodes=4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hacer el ajuste\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3e731-7497-49b6-b73e-8cbe53f4914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer las predicciones\n",
    "y_pred=rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a628dd3-2429-4372-abed-635ae4ae04c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualiza el puntaje \n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c226278-5a64-4dc0-a4d3-4082ab83bf4e",
   "metadata": {},
   "source": [
    "En el futuro, no les pedir√°n bagging, se prefiere utilizar Random Forestüå≥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64d353e",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">4.1 Predictores </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df4643cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpa 0.43120364790792415\n",
      "gmat 0.3311210055745527\n",
      "work_experience 0.2376753465175232\n"
     ]
    }
   ],
   "source": [
    "#Realiza el √°rbol de manera aleatoria\n",
    "random = RandomForestClassifier(n_estimators=100)\n",
    "#Despliega los par√°metros importantes o predictores\n",
    "random.fit(x_train,y_train)\n",
    "for nombre, score in zip(x.columns, random.feature_importances_):\n",
    "    print(nombre,score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb70dbd-53fa-410c-b10f-b1ed82ad7b02",
   "metadata": {},
   "source": [
    "El valor que arroja en cada variable es equivalente al nivel de importancia de la misma. En este caso el **gpa** es la variable que tiene mayor peso en la decisi√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ba27ae",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">5. Boosting </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695372ac",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">5.1 Adaboost </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f6553bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), learning_rate=0.1,\n",
       "                   n_estimators=100)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importar AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#Crear objeto de Adaboost con √°rboles de decisiones  \n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(),\n",
    "                         n_estimators=100,\n",
    "                         learning_rate=0.1)\n",
    "ada.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5de98d-7d62-4362-82cd-70af17bb877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular el puntaje de exactitud para adaboost\n",
    "y_pred=ada.predict(x_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca6697",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">5.2 Boosting con Gradiente </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "982dadee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f8ae735f670>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Crear un set de datos, especificamente una par√°bola para una mejor visualizaci√≥n \n",
    "m = 100\n",
    "x = np.linspace(-0.5,0.5,m)\n",
    "y = 25*x**2 + np.random.random(m) -0.5\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3621fb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear el primer predictor, utiliza √°rboles de decisiones y regularizalo con un max_depth=2\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "x = x.reshape(-1,1)\n",
    "arbol1 = DecisionTreeRegressor(max_depth=2)\n",
    "arbol1.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f7226a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular los errores residuales que \n",
    "#son la diferencia entre las predicciones del modelo y el valor de la variable a predecir\n",
    "y2 = y - arbol1.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88786d53-5b70-4b3e-9a69-d27d79c88128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear el segundo predictor en base a esos residuales.\n",
    "arbol2 = DecisionTreeRegressor(max_depth=2)\n",
    "arbol2.fit(x,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9d77214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizar que sucede si sumamos las predicciones del primer predictor con el segundo\n",
    "y_pred = sum(arbol.predict(x) for arbol in (arbol1, arbol2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3900c3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Repetir el mismo procedimiento para crear el √°rbol 3.\n",
    "y3 = y - arbol2.predict(x)\n",
    "arbol3 = DecisionTreeRegressor(max_depth=2)\n",
    "arbol3.fit(x,y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e1272dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora vamos a ver que sucede si sumamos los 3 √°rboles\n",
    "y_pred = sum(arbol.predict(x) for arbol in (arbol1, arbol2, arbol3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb9509cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear exactamente el mismo modelo que creamos antes\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, \n",
    "                                n_estimators=3, \n",
    "                                learning_rate=1.0)\n",
    "gbrt.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "53acbdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JASR\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#En este caso utilizaremos el error medio cuadrado.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
    "gbrt.fit(x_train, y_train)\n",
    "\n",
    "errores = [mean_squared_error(y_test,y_pred) for y_pred in gbrt.staged_predict(x_test)]\n",
    "mejor = np.argmin(errores)\n",
    "mejor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c550c62a-c6f0-4b0c-a2ed-e7396bb12e4c",
   "metadata": {},
   "source": [
    "En este caso el mejor caso es en **56** de los 120 √°rboles que probamos por lo que deber√≠amos crear nuestro modelo con 56 √°rboles de decisi√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f23683d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Evaluar el early stopping autom√°ticamente con XGBRegressor\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[1;32m      3\u001b[0m xgb \u001b[38;5;241m=\u001b[39m XGBRegressor()\n\u001b[1;32m      4\u001b[0m xgb\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "#Evaluar el early stopping autom√°ticamente con XGBRegressor\n",
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(x_train, y_train)\n",
    "y_pred = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d6f24924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:1.88028\n",
      "[1]\tvalidation_0-rmse:1.41283\n",
      "[2]\tvalidation_0-rmse:1.06651\n",
      "[3]\tvalidation_0-rmse:0.83850\n",
      "[4]\tvalidation_0-rmse:0.68930\n",
      "[5]\tvalidation_0-rmse:0.58440\n",
      "[6]\tvalidation_0-rmse:0.51411\n",
      "[7]\tvalidation_0-rmse:0.47995\n",
      "[8]\tvalidation_0-rmse:0.45692\n",
      "[9]\tvalidation_0-rmse:0.44813\n",
      "[10]\tvalidation_0-rmse:0.44354\n",
      "[11]\tvalidation_0-rmse:0.43750\n",
      "[12]\tvalidation_0-rmse:0.44223\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "xgb.fit(x_train, y_train, \n",
    "       eval_set=[(x_test,y_test)], early_stopping_rounds=1)\n",
    "y_pred = xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef37226",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">6. Stacking </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e8cee535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JASR\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingRegressor(estimators=[('arbol', DecisionTreeRegressor(max_depth=20)),\n",
       "                              ('lineal', LinearRegression()),\n",
       "                              ('random', RandomForestRegressor())])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importa los regresores necesarios StackingRegressor,LinearRegression, RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Generar el √°rbol de decisi√≥n\n",
    "arbol = DecisionTreeRegressor(max_depth=20)\n",
    "#Generar la regresi√≥n lineal\n",
    "lineal = LinearRegression()\n",
    "#Generar el bosque aleatorio\n",
    "random = RandomForestRegressor()\n",
    "#Genera los tres modelos \n",
    "stacking = StackingRegressor(estimators=[(\"arbol\", arbol),\n",
    "                            (\"lineal\", lineal),\n",
    "                          (\"random\", random)])\n",
    "#Utiliza Stacking\n",
    "stacking.fit(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
